{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BLOCK A â€” PREPROCESSING FOR GENE-SUMMED SNP DOSAGES\n",
    "# =========================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"--- Starting Data Preprocessing (gene-summed SNP dosages) ---\")\n",
    "\n",
    "# --- File paths (your originals) ---\n",
    "main_data_path    = '/Users/authorname/Downloads/all_chr_merged.parquet'\n",
    "gwas_catalog_path = '/Users/authorname/Downloads/MONDO_0004975_associations_export.tsv'\n",
    "string_links_path = '/Users/authorname/Downloads/9606.protein.links.v12.0.txt'      # unused here\n",
    "string_info_path  = '/Users/authorname/Downloads/9606.protein.info.v12.0.txt'       # unused here\n",
    "\n",
    "out_dir = \"/Users/authorname/Desktop/Projects/Genomics_LGBM(Genomics+Meta)_RATIOS_fixed_rfe\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# --- Load SNP matrix + GWAS mapping (your logic) ---\n",
    "df = pd.read_parquet(main_data_path)\n",
    "gwas_df = pd.read_csv(gwas_catalog_path, sep='\\t')\n",
    "\n",
    "gwas_df['riskAllele_cleaned'] = gwas_df['riskAllele'].astype(str).str.split('-').str[0].str.strip()\n",
    "gwas_df['first_gene'] = gwas_df['mappedGenes'].astype(str).str.split(',').str[0].str.strip()\n",
    "rs_map = gwas_df.dropna(subset=['riskAllele_cleaned', 'first_gene']) \\\n",
    "                .set_index('riskAllele_cleaned')['first_gene'].to_dict()\n",
    "\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "snp_cols = [c for c in df.columns if c.startswith('rs') or c.startswith('chr')]\n",
    "all_mapped_snps = {s: rs_map.get(s.split('_')[0]) for s in snp_cols if rs_map.get(s.split('_')[0])}\n",
    "\n",
    "# --- SNP QC (same thresholds as baseline) ---\n",
    "print(\"\\n--- SNP QC ---\")\n",
    "snps_to_map = list(all_mapped_snps.keys())\n",
    "maf = df[snps_to_map].apply(\n",
    "    lambda x: (2*x.eq(2).sum() + x.eq(1).sum()) / (2*x.notna().sum()),\n",
    "    axis=0\n",
    ")\n",
    "snps_to_remove_maf = maf[maf < 0.01].index.tolist()\n",
    "\n",
    "missing_rates = df[snps_to_map].isna().mean()\n",
    "snps_to_remove_callrate = missing_rates[missing_rates > 0.05].index.tolist()\n",
    "\n",
    "all_snps_to_remove = set(snps_to_remove_maf + snps_to_remove_callrate)\n",
    "all_mapped_snps_qc = {snp: gene for snp, gene in all_mapped_snps.items() if snp not in all_snps_to_remove}\n",
    "\n",
    "df_qc = df.drop(columns=list(all_snps_to_remove), errors=\"ignore\")\n",
    "snp_cols_qc = list(all_mapped_snps_qc.keys())\n",
    "print(f\"Retained {len(snp_cols_qc)} SNPs after QC.\")\n",
    "\n",
    "# --- Label assignment (your definitions) ---\n",
    "print(\"\\n--- Label assignment ---\")\n",
    "df_qc['age_death'] = pd.to_numeric(df_qc['age_death'].astype(str).replace('90+', '90', regex=False), errors='coerce')\n",
    "\n",
    "conditions = [\n",
    "    (df_qc['ceradsc'].isin([1, 2])) & (df_qc['cogdx'].isin([4, 5])),\n",
    "    (df_qc['ceradsc'].isin([1, 2])) & ~(df_qc['cogdx'].isin([4, 5])),\n",
    "    ~(df_qc['ceradsc'].isin([1, 2])) & (df_qc['cogdx'].isin([4, 5])),\n",
    "    ~(df_qc['ceradsc'].isin([1, 2])) & ~(df_qc['cogdx'].isin([4, 5]))\n",
    "]\n",
    "choices = ['Typical AD', 'Resilient', 'Symptomatic Non-AD', 'Healthy Control']\n",
    "df_qc['patient_group'] = np.select(conditions, choices, default='Unknown')\n",
    "df_qc = df_qc[df_qc['patient_group'] != 'Unknown'].reset_index(drop=True)\n",
    "\n",
    "print(\"Patient Group Counts:\")\n",
    "print(df_qc['patient_group'].value_counts())\n",
    "\n",
    "# --- Demographics + SNP handling (mirror baseline) ---\n",
    "numeric_features     = ['age_death', 'educ']\n",
    "categorical_features = ['apoe_genotype']\n",
    "binary_features      = ['msex']\n",
    "snp_features         = snp_cols_qc\n",
    "\n",
    "feature_df = df_qc[['projid'] + numeric_features + categorical_features + binary_features + snp_features].copy()\n",
    "\n",
    "# Impute numeric only\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "feature_df[numeric_features] = imputer_num.fit_transform(feature_df[numeric_features])\n",
    "\n",
    "# Keep SNP NaNs; round observed to {0,1,2}\n",
    "snp_block = feature_df[snp_features].astype(float)\n",
    "mask = ~snp_block.isna()\n",
    "rounded = np.empty_like(snp_block.values)\n",
    "rounded[:] = np.nan\n",
    "rounded[mask.values] = np.rint(snp_block.values[mask.values])\n",
    "snp_block = pd.DataFrame(rounded, columns=snp_features, index=feature_df.index)\n",
    "feature_df[snp_features] = snp_block\n",
    "\n",
    "feature_df[binary_features] = feature_df[binary_features].astype(int)\n",
    "\n",
    "# Sum SNPs â†’ genes (ignore NaN; keep NaN if all missing)\n",
    "print(\"\\n--- Building gene-summed dosage matrix ---\")\n",
    "gene_to_snps = defaultdict(list)\n",
    "for snp, gene in all_mapped_snps_qc.items():\n",
    "    gene_to_snps[gene].append(snp)\n",
    "\n",
    "gene_dosage_df = pd.DataFrame(index=feature_df.index)\n",
    "for gene, snp_list in gene_to_snps.items():\n",
    "    vals = feature_df[snp_list].to_numpy(dtype=float)\n",
    "    gsum = np.nansum(vals, axis=1)\n",
    "    all_missing = np.isnan(vals).all(axis=1)\n",
    "    gsum[all_missing] = np.nan\n",
    "    gene_dosage_df[gene] = gsum\n",
    "\n",
    "# APOE OHE\n",
    "try:\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "apoe_encoded = ohe.fit_transform(feature_df[['apoe_genotype']])\n",
    "apoe_df = pd.DataFrame(apoe_encoded, columns=ohe.get_feature_names_out(), index=feature_df.index)\n",
    "\n",
    "# Final feature table: demographics + APOE OHE + gene_sums\n",
    "X_gene_based = pd.concat(\n",
    "    [feature_df[numeric_features + binary_features].reset_index(drop=True),\n",
    "     apoe_df.reset_index(drop=True),\n",
    "     gene_dosage_df.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "X_gene_based.columns = X_gene_based.columns.astype(str)\n",
    "\n",
    "# Labels & encoders (to match your baseline later)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_qc['patient_group'].astype(str).values)\n",
    "y_labels = df_qc['patient_group'].astype(str).values\n",
    "\n",
    "# Stratifier exactly like your baseline\n",
    "y_strat = (df_qc['patient_group'].astype(str) + \"_\" + df_qc['msex'].astype(int).astype(str)).values\n",
    "\n",
    "# Keep list of pure gene columns (for ratio generation later)\n",
    "non_gene_cols = set(numeric_features + binary_features + list(apoe_df.columns))\n",
    "gene_cols = [c for c in X_gene_based.columns if c not in non_gene_cols]\n",
    "\n",
    "# Groups\n",
    "groups = df_qc['projid'].astype(str).values\n",
    "\n",
    "print(f\"\\nX_gene_based shape: {X_gene_based.shape}\")\n",
    "print(\"Label to Class Name mapping:\")\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i}: {class_name}\")\n",
    "print(f\"Total genes available for ratio generation: {len(gene_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BLOCK B â€” READ BASELINE GENOMICS PICKLES & COLLECT STABLE GENES\n",
    "# =========================\n",
    "import os, pickle\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "print(\"\\n--- Reading baseline GENOMICS LGBM pickles for stable features (â‰¥2/5 seeds) ---\")\n",
    "\n",
    "baseline_models_dir = \"/Users/authorname/Desktop/Projects/ml4h_project/LGBM(Genes+Demo)\"\n",
    "\n",
    "# Match EXACT names you saved with in baseline training\n",
    "classes = [\n",
    "    \"Healthy_Control\",\n",
    "    \"Resilient\",\n",
    "    \"Symptomatic_Non-AD\",\n",
    "    \"Typical_AD\"\n",
    "]\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "\n",
    "def _get_trained_estimator_and_features(automl_obj):\n",
    "    model = getattr(automl_obj, \"model\", None)\n",
    "    est = getattr(model, \"estimator\", model)\n",
    "    if est is None:\n",
    "        return None, None\n",
    "    if hasattr(automl_obj, \"feature_names_in_\") and automl_obj.feature_names_in_ is not None:\n",
    "        feat_names = list(automl_obj.feature_names_in_)\n",
    "    elif hasattr(est, \"feature_name_\") and est.feature_name_ is not None:\n",
    "        feat_names = list(est.feature_name_)\n",
    "    else:\n",
    "        feat_names = None\n",
    "    return est, feat_names\n",
    "\n",
    "feature_counts_per_class = defaultdict(Counter)\n",
    "\n",
    "for seed in seeds:\n",
    "    for cls in classes:\n",
    "        pkl_path = os.path.join(baseline_models_dir, f\"seed{seed}_{cls}_automl.pkl\")\n",
    "        if not os.path.exists(pkl_path):\n",
    "            print(f\"[WARN] Missing: {pkl_path}\")\n",
    "            continue\n",
    "        try:\n",
    "            with open(pkl_path, \"rb\") as f:\n",
    "                automl = pickle.load(f)\n",
    "            est, feature_names = _get_trained_estimator_and_features(automl)\n",
    "            if est is None or not hasattr(est, \"feature_importances_\"):\n",
    "                print(f\"[WARN] No feature importances in {pkl_path}\")\n",
    "                continue\n",
    "            importances = est.feature_importances_\n",
    "            nonzero_genes = [f for f, imp in zip(feature_names, importances) if imp > 0 and f in gene_cols]\n",
    "            feature_counts_per_class[cls].update(nonzero_genes)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {pkl_path}: {e}\")\n",
    "\n",
    "# keep genes seen in â‰¥2 seeds\n",
    "shared_features_per_class = {\n",
    "    cls: [feat for feat, cnt in cnts.items() if cnt >= 2]\n",
    "    for cls, cnts in feature_counts_per_class.items()\n",
    "}\n",
    "\n",
    "for cls in classes:\n",
    "    feats = shared_features_per_class.get(cls, [])\n",
    "    print(f\"[{cls}] Stable genes (â‰¥2 seeds): {len(feats)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BLOCK C â€” RATIO TRAINING WITH RFE (GENE-BASED) - CORRECTED\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "out_dir = \"/Users/authorname/Desktop/Projects/Genomics_LGBM(Genomics+Meta)_RATIOS_Demo\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# ---- Config (assumes variables from Blocks A & B are loaded) ----\n",
    "# `out_dir`, `label_encoder`, `y_labels`, `y_strat`, `groups`,\n",
    "# `X_gene_based`, `gene_cols`, and `shared_features_per_class`\n",
    "# should all be available from the previous blocks.\n",
    "\n",
    "# --- ðŸ’¡ FIX: Use the class names with underscores to match the keys ---\n",
    "# --- in the `shared_features_per_class` dictionary from Block B. ---\n",
    "classes = [\n",
    "    \"Healthy_Control\",\n",
    "    \"Resilient\",\n",
    "    \"Symptomatic_Non-AD\",\n",
    "    \"Typical_AD\"\n",
    "]\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "\n",
    "def safe_cls(c):\n",
    "    return c.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "\n",
    "# ---- Gene-only matrix for creating ratios ----\n",
    "X_genes_only = X_gene_based[gene_cols].copy()\n",
    "\n",
    "# >>> ADDED: demographics + APOE OHE column list (not used in RFE)\n",
    "demo_base = ['age_death', 'educ', 'msex']\n",
    "apoe_cols = [c for c in X_gene_based.columns if c.startswith('apoe_genotype_')]\n",
    "demo_cols = demo_base + apoe_cols\n",
    "\n",
    "# ---- Custom group-aware stratified split function (no changes needed) ----\n",
    "def group_stratified_shuffle_split(df_index, strata_all, groups_all, test_size=0.30, random_state=0):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    data = pd.DataFrame({\"idx\": df_index, \"strata\": strata_all, \"group\": groups_all})\n",
    "    grp_mode = data.groupby(\"group\")[\"strata\"].agg(lambda s: s.value_counts().idxmax())\n",
    "    grp_mode = grp_mode.sample(frac=1.0, random_state=random_state)\n",
    "\n",
    "    train_groups, test_groups = [], []\n",
    "    for _, grp_ids in grp_mode.groupby(grp_mode.values):\n",
    "        g_list = list(grp_ids.index)\n",
    "        rng.shuffle(g_list)\n",
    "        n_test = max(1, int(round(test_size * len(g_list))))\n",
    "        test_groups.extend(g_list[:n_test])\n",
    "        train_groups.extend(g_list[n_test:])\n",
    "\n",
    "    train_mask = np.isin(groups_all, train_groups)\n",
    "    test_mask  = np.isin(groups_all, test_groups)\n",
    "    return np.where(train_mask)[0], np.where(test_mask)[0]\n",
    "\n",
    "# ---- Main Training Loop ----\n",
    "for cls in classes:\n",
    "    # 1. Select stable genes for the current class\n",
    "    # Now, `cls` will be \"Healthy_Control\", which correctly finds the 7 genes.\n",
    "    class_genes = shared_features_per_class.get(cls, [])\n",
    "    print(f\"\\n[{cls}] Using {len(class_genes)} stable genes for ratio generation...\")\n",
    "\n",
    "    if len(class_genes) < 2:\n",
    "        print(f\"-> Skipping [{cls}]: Not enough genes to form ratios (need at least 2).\")\n",
    "        continue\n",
    "\n",
    "    # 2. Generate all pairwise ratios from the selected genes\n",
    "    ratio_cols = []\n",
    "    ratio_data = []\n",
    "    epsilon = 1e-8  # Small value to prevent division by zero\n",
    "\n",
    "    for g1, g2 in combinations(class_genes, 2):\n",
    "        rname = f\"{g1}_div_{g2}\"\n",
    "        ratio_cols.append(rname)\n",
    "        # Add epsilon for numerical stability\n",
    "        ratio_data.append(X_genes_only[g1].values / (X_genes_only[g2].values + epsilon))\n",
    "\n",
    "    X_ratio_cls = pd.DataFrame(np.column_stack(ratio_data), columns=ratio_cols, index=X_genes_only.index)\n",
    "    print(f\"-> Generated {X_ratio_cls.shape[1]} ratio features for [{cls}].\")\n",
    "\n",
    "    # 3. Loop through seeds to perform train/test split, RFE, and model training\n",
    "    for seed in seeds:\n",
    "        # A. Split data into training and testing sets\n",
    "        tr_idx, te_idx = group_stratified_shuffle_split(\n",
    "            df_index=np.arange(len(X_ratio_cls)),\n",
    "            strata_all=y_strat,\n",
    "            groups_all=groups,\n",
    "            test_size=0.30,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "        # B. Create initial data splits with all generated ratios\n",
    "        X_train_full = X_ratio_cls.iloc[tr_idx]\n",
    "        X_test_full  = X_ratio_cls.iloc[te_idx]\n",
    "        y_train_full = pd.Series(y_labels).iloc[tr_idx].values\n",
    "        y_test_full  = pd.Series(y_labels).iloc[te_idx].values\n",
    "\n",
    "        print(f\"[{cls} | Seed {seed}] Train/Test split: {len(tr_idx)} / {len(te_idx)}\")\n",
    "\n",
    "        # C. Create binary labels for one-vs-all classification\n",
    "        # We must convert the underscore version back to the space version to match `y_labels`\n",
    "        y_train = (y_train_full == cls.replace(\"_\", \" \")).astype(int)\n",
    "        y_test  = (y_test_full == cls.replace(\"_\", \" \")).astype(int)\n",
    "\n",
    "\n",
    "        # D. Perform RFE on the TRAINING data ONLY\n",
    "        rfe_model = LGBMClassifier(n_estimators=100, random_state=seed)\n",
    "        n_select  = min(100, X_train_full.shape[1]) # Select up to 100 features\n",
    "        rfe = RFE(estimator=rfe_model, n_features_to_select=n_select, step=0.1)\n",
    "        rfe.fit(X_train_full, y_train)\n",
    "\n",
    "        # E. Filter both train and test sets using the features selected by RFE\n",
    "        selected_cols = list(X_train_full.columns[rfe.get_support()])\n",
    "        X_train = X_train_full[selected_cols]\n",
    "        X_test  = X_test_full[selected_cols]\n",
    "        print(f\"-> Post-RFE features selected: {len(selected_cols)}\")\n",
    "\n",
    "        X_train = pd.concat([X_train, X_gene_based.loc[X_train.index, demo_cols]], axis=1)\n",
    "        X_test  = pd.concat([X_test,  X_gene_based.loc[X_test.index,  demo_cols]], axis=1)\n",
    "\n",
    "        # F. Train the final model using AutoML\n",
    "        automl = AutoML()\n",
    "        settings = {\n",
    "            \"time_budget\": 100,\n",
    "            \"metric\": \"roc_auc\",\n",
    "            \"task\": \"classification\",\n",
    "            \"eval_method\": \"cv\",\n",
    "            \"estimator_list\": [\"lgbm\"],\n",
    "            \"log_file_name\": os.path.join(out_dir, f\"flaml_seed{seed}_{safe_cls(cls)}.log\"),\n",
    "            \"seed\": seed,\n",
    "        }\n",
    "\n",
    "        automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "        automl.pickle(os.path.join(out_dir, f\"seed{seed}_{safe_cls(cls)}_automl.pkl\"))\n",
    "\n",
    "        # G. Evaluate performance and save results\n",
    "        y_score = automl.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_score) if (y_test.sum() > 0 and y_test.sum() < len(y_test)) else float(\"nan\")\n",
    "        print(f\"  -> FINAL AUC = {auc:.4f}\\n\")\n",
    "\n",
    "        out_csv = os.path.join(out_dir, f\"seed{seed}_{safe_cls(cls)}.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"y_true\": y_test.astype(int),\n",
    "            \"y_score\": y_score.astype(float)\n",
    "        }).to_csv(out_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# ==== CONFIG ====\n",
    "folder = \"/Users/authorname/Desktop/Projects/Genomics_LGBM(Genomics+Meta)_RATIOS_Demo\"\n",
    "\n",
    "# ---- Collect CSVs (pattern: seed{seed}_{Class}.csv) ----\n",
    "files = glob.glob(os.path.join(folder, \"seed*_*/*.csv\"))  # if you saved in subfolders; else:\n",
    "if not files:\n",
    "    files = glob.glob(os.path.join(folder, \"seed*_*.csv\"))\n",
    "\n",
    "def class_from_path(p):\n",
    "    base = os.path.basename(p)\n",
    "    # handles: seed5_Typical_AD.csv  OR seed5_Typical_AD_plus_something.csv\n",
    "    return \"_\".join(base.split(\"_\")[1:]).rsplit(\".csv\", 1)[0]\n",
    "\n",
    "class_names = sorted(set(class_from_path(p) for p in files))\n",
    "\n",
    "# ==== Plot ====\n",
    "fpr_grid = np.linspace(0.0, 1.0, 200)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "auc_summary_rows = []\n",
    "\n",
    "for cls in class_names:\n",
    "    cls_files = sorted(glob.glob(os.path.join(folder, f\"seed*_{cls}.csv\")))\n",
    "    if not cls_files:\n",
    "        continue\n",
    "\n",
    "    tprs_interp, aucs = [], []\n",
    "\n",
    "    for path in cls_files:\n",
    "        df = pd.read_csv(path)\n",
    "        y_true = df[\"y_true\"].astype(int).values\n",
    "        y_score = df[\"y_score\"].astype(float).values\n",
    "\n",
    "        # guard against degenerate splits\n",
    "        if y_true.sum() == 0 or y_true.sum() == len(y_true):\n",
    "            continue\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "\n",
    "        # ensure strictly increasing FPR for interpolation\n",
    "        uniq_idx = np.unique(fpr, return_index=True)[1]\n",
    "        fpr_u = fpr[uniq_idx]\n",
    "        tpr_u = tpr[uniq_idx]\n",
    "\n",
    "        # interpolate on common grid\n",
    "        tpr_i = np.interp(fpr_grid, fpr_u, tpr_u)\n",
    "        tpr_i[0] = 0.0\n",
    "        tpr_i[-1] = 1.0\n",
    "        tprs_interp.append(tpr_i)\n",
    "\n",
    "        aucs.append(auc(fpr_u, tpr_u))\n",
    "\n",
    "    if not tprs_interp:\n",
    "        print(f\"[WARN] No valid ROC curves for class {cls} (all-positive or all-negative splits?)\")\n",
    "        continue\n",
    "\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    std_tpr  = np.std(tprs_interp, axis=0)\n",
    "    mean_auc = float(np.mean(aucs))\n",
    "    std_auc  = float(np.std(aucs))\n",
    "\n",
    "    # pretty label\n",
    "    label_cls = cls.replace(\"_\", \" \")\n",
    "    plt.plot(fpr_grid, mean_tpr, lw=2,\n",
    "             label=f\"{label_cls} (AUC = {mean_auc:.3f} Â± {std_auc:.3f})\")\n",
    "    plt.fill_between(fpr_grid,\n",
    "                     np.clip(mean_tpr - std_tpr, 0, 1),\n",
    "                     np.clip(mean_tpr + std_tpr, 0, 1),\n",
    "                     alpha=0.15)\n",
    "\n",
    "    auc_summary_rows.append({\"Class\": label_cls, \"Mean_AUC\": mean_auc, \"Std_AUC\": std_auc, \"N\": len(aucs)})\n",
    "\n",
    "# chance line\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Chance (AUC = 0.50)\")\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Genetic-Ratios with Demo (LGBM)\")\n",
    "plt.legend(loc=\"lower right\", fontsize=9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# optional: save figure and AUC table\n",
    "plot_path = os.path.join(folder, \"roc_mean_across_seeds.png\")\n",
    "plt.savefig(plot_path, dpi=200)\n",
    "print(f\"Saved plot to: {plot_path}\")\n",
    "\n",
    "if auc_summary_rows:\n",
    "    auc_df = pd.DataFrame(auc_summary_rows).sort_values(\"Class\")\n",
    "    auc_csv = os.path.join(folder, \"roc_auc_summary.csv\")\n",
    "    auc_df.to_csv(auc_csv, index=False)\n",
    "    print(f\"Saved AUC summary to: {auc_csv}\")\n",
    "    print(auc_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "# ====== CONFIG ======\n",
    "folder = \"/Users/authorname/Desktop/Projects/Genomics_LGBM(Genomics+Meta)_RATIOS_fixed_rfe\"\n",
    "\n",
    "def class_from_path(p):\n",
    "    base = os.path.basename(p)\n",
    "    return \"_\".join(base.split(\"_\")[1:]).rsplit(\".csv\", 1)[0]\n",
    "\n",
    "files = glob.glob(os.path.join(folder, \"seed*_*.csv\"))\n",
    "class_names = sorted(set(class_from_path(p) for p in files))\n",
    "\n",
    "recall_grid = np.linspace(0.0, 1.0, 200)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for cls in class_names:\n",
    "    cls_files = sorted(glob.glob(os.path.join(folder, f\"seed*_{cls}.csv\")))\n",
    "    if not cls_files:\n",
    "        print(f\"[warn] No CSVs found for class={cls}\")\n",
    "        continue\n",
    "\n",
    "    prec_interp_list, aps = [], []\n",
    "    prevalences = []  # for PR baseline\n",
    "\n",
    "    for path in cls_files:\n",
    "        df = pd.read_csv(path)\n",
    "        y_true  = df[\"y_true\"].astype(int).values\n",
    "        y_score = df[\"y_score\"].astype(float).values\n",
    "\n",
    "        # --- PR curve ---\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "        # Deduplicate recall for interpolation\n",
    "        uniq_idx = np.unique(recall, return_index=True)[1]\n",
    "        r_u, p_u = recall[uniq_idx], precision[uniq_idx]\n",
    "\n",
    "        # Interpolate precision onto a common recall grid\n",
    "        p_i = np.interp(recall_grid, r_u, p_u, left=p_u[0], right=p_u[-1])\n",
    "        prec_interp_list.append(p_i)\n",
    "\n",
    "        # Average Precision and prevalence (positive rate) for baseline\n",
    "        aps.append(average_precision_score(y_true, y_score))\n",
    "        prevalences.append(y_true.mean())\n",
    "\n",
    "    if not prec_interp_list:\n",
    "        continue\n",
    "\n",
    "    mean_prec = np.mean(prec_interp_list, axis=0)\n",
    "    std_prec  = np.std(prec_interp_list, axis=0)\n",
    "    mean_ap   = float(np.mean(aps))\n",
    "    std_ap    = float(np.std(aps))\n",
    "\n",
    "    # Plot PR curve (mean Â± SD)\n",
    "    line, = plt.plot(recall_grid, mean_prec, lw=2,\n",
    "                     label=f\"{cls.replace('_',' ')} (AP = {mean_ap:.3f} Â± {std_ap:.3f})\")\n",
    "    plt.fill_between(recall_grid,\n",
    "                     np.clip(mean_prec - std_prec, 0, 1),\n",
    "                     np.clip(mean_prec + std_prec, 0, 1),\n",
    "                     alpha=0.15, color=line.get_color())\n",
    "\n",
    "    # --- Add class-specific PR baseline (chance level = prevalence) ---\n",
    "    prev_mean = float(np.mean(prevalences))\n",
    "    prev_sd   = float(np.std(prevalences))\n",
    "    # dashed baseline\n",
    "    plt.hlines(prev_mean, 0, 1, colors=line.get_color(), linestyles=\"--\", alpha=0.6)\n",
    "    # light band for Â±1 SD\n",
    "    low = max(0.0, prev_mean - prev_sd)\n",
    "    high = min(1.0, prev_mean + prev_sd)\n",
    "    plt.fill_between([0, 1], [low, low], [high, high],\n",
    "                     color=line.get_color(), alpha=0.08)\n",
    "\n",
    "    # Add a tiny annotation so readers know the baseline value\n",
    "    plt.text(1.002, prev_mean, f\"{prev_mean:.2f}\",\n",
    "             color=line.get_color(), va=\"center\", fontsize=8)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(\"Genomic-Ratios (LGBM)\\nPrecisionâ€“Recall (mean Â± SD across seeds; dashed = prevalence)\")\n",
    "plt.legend(loc='upper right', fontsize=9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FEATURE IMPORTANCE PLOTS (GENE RATIOS)\n",
    "# =========================\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === CONFIG ===\n",
    "out_dir = \"/Users/authorname/Desktop/Projects/Genomics_LGBM(Genomics+Meta)_RATIOS_fixed_rfe\"   # same folder where your ratio models were saved\n",
    "classes = list(label_encoder.classes_)    # e.g., [\"Healthy Control\", \"Resilient\", ...]\n",
    "seeds   = [1, 2, 3, 4, 5]\n",
    "top_n   = 20  # number of top features to display\n",
    "\n",
    "def safe_cls(c):\n",
    "    return c.replace(\"+\", \"plus\").replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "# === MAIN LOOP ===\n",
    "\n",
    "for cls in classes:\n",
    "    feature_importance_list = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        pkl_path = os.path.join(out_dir, f\"seed{seed}_{safe_cls(cls)}_automl.pkl\")\n",
    "        if not os.path.exists(pkl_path):\n",
    "            print(f\"Missing: {pkl_path}\")\n",
    "            continue\n",
    "\n",
    "        with open(pkl_path, \"rb\") as f:\n",
    "            automl = pickle.load(f)\n",
    "\n",
    "        model = automl.model.estimator\n",
    "        importances = model.feature_importances_\n",
    "        features = automl.feature_names_in_\n",
    "\n",
    "        # Normalize importance\n",
    "        norm_importance = importances / importances.sum()\n",
    "        feature_importance_list.append(pd.Series(norm_importance, index=features))\n",
    "\n",
    "    if not feature_importance_list:\n",
    "        print(f\"No data for class: {cls}\")\n",
    "        continue\n",
    "\n",
    "    # Combine across seeds\n",
    "    df_importances = pd.concat(feature_importance_list, axis=1)\n",
    "    df_importances.columns = [f\"seed{i}\" for i in range(len(df_importances.columns))]\n",
    "\n",
    "    # Compute mean across seeds\n",
    "    df_importances[\"mean\"] = df_importances.mean(axis=1)\n",
    "\n",
    "    # Take top N\n",
    "    df_top = df_importances.sort_values(\"mean\", ascending=False).head(top_n)\n",
    "\n",
    "    # Replace \"_div_\" with \" : \"\n",
    "    df_top[\"mapped_name\"] = df_top.index.str.replace(\"_div_\", \" : \")\n",
    "\n",
    "    # === Plot ===\n",
    "    plt.figure(figsize=(10, max(6, 0.3 * top_n)))\n",
    "    plt.barh(y=df_top[\"mapped_name\"][::-1], width=df_top[\"mean\"][::-1], color=\"steelblue\", alpha=0.85)\n",
    "\n",
    "    plt.xlabel(\"Mean Normalized Feature Importance\")\n",
    "    plt.title(f\"Top {top_n} Genetic Ratios â€” Class {cls}\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, axis=\"x\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "    # Save plot\n",
    "    plot_path = os.path.join(out_dir, f\"top{top_n}_ratios_{safe_cls(cls)}.png\")\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Saved: {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neuro_240)",
   "language": "python",
   "name": "neuro_240"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
