{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- General Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Scikit-learn Imports ---\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# --- AutoML Imports ---\n",
    "from flaml import AutoML\n",
    "\n",
    "# --- GNN Imports ---\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Ignore some common warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"--- Starting Data Preprocessing ---\")\n",
    "\n",
    "# --- Step 1: Define File Paths ---\n",
    "main_data_path = '/Users/authorname/Downloads/all_chr_merged.parquet'\n",
    "gwas_catalog_path = '/Users/authorname/Downloads/MONDO_0004975_associations_export.tsv'\n",
    "string_links_path = '/Users/authorname/Downloads/9606.protein.links.v12.0.txt'\n",
    "string_info_path = '/Users/authorname/Downloads/9606.protein.info.v12.0.txt'\n",
    "\n",
    "# --- Step 2: Load Raw Data and Map SNPs to Genes ---\n",
    "print(\"--- Step 2: Loading Data and Mapping SNPs to Genes ---\")\n",
    "df = pd.read_parquet(main_data_path)\n",
    "gwas_df = pd.read_csv(gwas_catalog_path, sep='\\t')\n",
    "\n",
    "gwas_df['riskAllele_cleaned'] = gwas_df['riskAllele'].str.split('-').str[0].str.strip()\n",
    "gwas_df['first_gene'] = gwas_df['mappedGenes'].str.split(',').str[0].str.strip()\n",
    "rs_map = gwas_df.dropna(subset=['riskAllele_cleaned', 'first_gene']).set_index('riskAllele_cleaned')['first_gene'].to_dict()\n",
    "\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "snp_cols = [col for col in df.columns if col.startswith('rs') or col.startswith('chr')]\n",
    "all_mapped_snps = {snp_col: rs_map.get(snp_col.split('_')[0]) for snp_col in snp_cols if rs_map.get(snp_col.split('_')[0])}\n",
    "\n",
    "# --- Step 3: Perform SNP Quality Control ---\n",
    "print(\"\\n--- Step 3: Performing SNP Quality Control ---\")\n",
    "snps_to_map = list(all_mapped_snps.keys())\n",
    "maf = df[snps_to_map].apply(lambda x: (2*x.eq(2).sum() + x.eq(1).sum()) / (2*x.notna().sum()), axis=0)\n",
    "snps_to_remove_maf = maf[maf < 0.01].index.tolist()\n",
    "missing_rates = df[snps_to_map].isna().mean()\n",
    "snps_to_remove_callrate = missing_rates[missing_rates > 0.05].index.tolist()\n",
    "all_snps_to_remove = set(snps_to_remove_maf + snps_to_remove_callrate)\n",
    "\n",
    "all_mapped_snps_qc = {snp: gene for snp, gene in all_mapped_snps.items() if snp not in all_snps_to_remove}\n",
    "df_qc = df.drop(columns=list(all_snps_to_remove))\n",
    "snp_cols_qc = list(all_mapped_snps_qc.keys())\n",
    "print(f\"Retained {len(snp_cols_qc)} SNPs after QC.\")\n",
    "\n",
    "# --- Step 4: Assign Labels ---\n",
    "print(\"\\n--- Step 4: Assigning Labels ---\")\n",
    "df_qc['age_death'] = pd.to_numeric(df_qc['age_death'].astype(str).replace('90+', '90', regex=False), errors='coerce')\n",
    "# The explicit class definitions you provided\n",
    "conditions = [\n",
    "    (df_qc['ceradsc'].isin([1, 2])) & (df_qc['cogdx'].isin([4, 5])),\n",
    "    (df_qc['ceradsc'].isin([1, 2])) & ~(df_qc['cogdx'].isin([4, 5])),\n",
    "    ~(df_qc['ceradsc'].isin([1, 2])) & (df_qc['cogdx'].isin([4, 5])),\n",
    "    ~(df_qc['ceradsc'].isin([1, 2])) & ~(df_qc['cogdx'].isin([4, 5]))\n",
    "]\n",
    "choices = ['Typical AD', 'Resilient', 'Symptomatic Non-AD', 'Healthy Control']\n",
    "df_qc['patient_group'] = np.select(conditions, choices, default='Unknown')\n",
    "df_qc = df_qc[df_qc['patient_group'] != 'Unknown'] # Remove any unclassified patients\n",
    "\n",
    "print(\"Patient Group Counts:\")\n",
    "print(df_qc['patient_group'].value_counts())\n",
    "\n",
    "# --- Step 5: Create a gene-summed feature matrix with demographic covariates ---\n",
    "print(\"\\n--- Step 5: Creating Gene-Summed Feature Matrix ---\")\n",
    "\n",
    "# Define demographic and binary variables (reusing your structure)\n",
    "numeric_features = ['age_death', 'educ']\n",
    "categorical_features = ['apoe_genotype']\n",
    "binary_features = ['msex']\n",
    "snp_features = snp_cols_qc\n",
    "\n",
    "# Extract necessary data\n",
    "feature_df = df_qc[['projid'] + numeric_features + categorical_features + binary_features + snp_features].copy()\n",
    "\n",
    "# Impute missing numeric values ONLY (no scaling)\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "feature_df[numeric_features] = imputer_num.fit_transform(feature_df[numeric_features])\n",
    "\n",
    "# --- NO SNP IMPUTATION ---\n",
    "# Keep SNPs as-is (may contain NaN); round only observed values to {0,1,2}\n",
    "snp_block = feature_df[snp_features].astype(float)\n",
    "mask = ~snp_block.isna()\n",
    "rounded = np.empty_like(snp_block.values)\n",
    "rounded[:] = np.nan\n",
    "rounded[mask.values] = np.rint(snp_block.values[mask.values])\n",
    "snp_block = pd.DataFrame(rounded, columns=snp_features, index=feature_df.index)\n",
    "feature_df[snp_features] = snp_block\n",
    "\n",
    "feature_df[binary_features] = feature_df[binary_features].astype(int)\n",
    "\n",
    "# --- Step 5a: Create gene-summed dosage features (no scaling) ---\n",
    "print(\"Summing SNPs into gene-level features...\")\n",
    "\n",
    "gene_to_snps = defaultdict(list)\n",
    "for snp, gene in all_mapped_snps_qc.items():\n",
    "    gene_to_snps[gene].append(snp)\n",
    "\n",
    "gene_dosage_df = pd.DataFrame(index=feature_df.index)\n",
    "for gene, snp_list in gene_to_snps.items():\n",
    "    vals = feature_df[snp_list].to_numpy(dtype=float)\n",
    "    # Sum across SNPs, ignoring NaNs\n",
    "    gene_sum = np.nansum(vals, axis=1)\n",
    "    # If ALL SNPs for a sample are NaN, keep NaN (avoid fabricating zeros)\n",
    "    all_missing = np.isnan(vals).all(axis=1)\n",
    "    gene_sum[all_missing] = np.nan\n",
    "    gene_dosage_df[gene] = gene_sum  # keep float so NaNs are preserved\n",
    "\n",
    "# One-hot encode APOE genotype (keep as before)\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "apoe_encoded = ohe.fit_transform(feature_df[categorical_features])\n",
    "apoe_df = pd.DataFrame(apoe_encoded, columns=ohe.get_feature_names_out(), index=feature_df.index)\n",
    "\n",
    "# Final gene-based feature matrix (raw age/educ, raw binary, APOE OHE, gene sums with NaNs)\n",
    "X_gene_based = pd.concat([\n",
    "    feature_df[numeric_features + binary_features].reset_index(drop=True),\n",
    "    apoe_df.reset_index(drop=True),\n",
    "    gene_dosage_df.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "X_gene_based.columns = X_gene_based.columns.astype(str)\n",
    "print(f\"Created gene-summed + demographic feature matrix with shape: {X_gene_based.shape}\")\n",
    "\n",
    "print(f\"Created gene-summed + demographic feature matrix with shape: {X_gene_based.shape}\")\n",
    "\n",
    "\n",
    "# --- Step 6: Encode Labels and Create Train-Test Split ---\n",
    "print(\"\\n--- Step 6: Encoding Labels and Creating Train-Test Split ---\")\n",
    "y_labels = df_qc['patient_group'].values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_labels)\n",
    "\n",
    "# Using StratifiedShuffleSplit for a single 70-30 split\n",
    "\n",
    "y_strat = df_qc['patient_group'].astype(str) + \"_\" + df_qc['msex'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1, 2, 3, 4, 5,]\n",
    "\n",
    "from collections import defaultdict\n",
    "rf_auc_by_seed = defaultdict(list)\n",
    "\n",
    "import os\n",
    "out_dir = \"/Users/authorname/Desktop/Projects/ml4h_project/RF(Genes+Demo)\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# REPLACE your existing sss+for-header with the two lines below:\n",
    "for seed in seeds:  \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=seed)\n",
    "    for train_index, test_index in sss.split(X_gene_based, y_strat):\n",
    "        X_train, X_test = X_gene_based.iloc[train_index], X_gene_based.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Keep track of patient IDs for GNN mapping\n",
    "        train_projids = df_qc.iloc[train_index]['projid']\n",
    "        test_projids = df_qc.iloc[test_index]['projid']\n",
    "\n",
    "\n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Test set shape: {X_test.shape}\")\n",
    "    print(\"Label to Class Name mapping:\")\n",
    "    for i, class_name in enumerate(label_encoder.classes_):\n",
    "        print(f\"{i}: {class_name}\")\n",
    "\n",
    "    from flaml import AutoML\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "\n",
    "    \n",
    "\n",
    "    # =============================================================================\n",
    "    # SECTION 3b: AutoML with FLAML (ONE-VS-REST) - Random Forest Baseline\n",
    "    # =============================================================================\n",
    "    print(\"\\n\\n--- Training AutoML Random Forest Baseline (One-vs-Rest) ---\")\n",
    "\n",
    "    rf_results = {}\n",
    "    rf_objects = {}\n",
    "\n",
    "\n",
    "\n",
    "    for i, class_name in enumerate(label_encoder.classes_):\n",
    "        print(f\"\\n--- RF baseline for class: '{class_name}' vs. Rest ---\")\n",
    "        \n",
    "        y_train_ovr = (y_train == i).astype(int)\n",
    "        y_test_ovr  = (y_test  == i).astype(int)\n",
    "\n",
    "        if np.sum(y_test_ovr) < 1:\n",
    "            print(f\"Skipping class '{class_name}' due to no positive samples in the test set.\")\n",
    "            continue\n",
    "\n",
    "        automl_rf = AutoML()\n",
    "        automl_settings_rf = {\n",
    "            \"time_budget\": 100,\n",
    "            \"metric\": \"roc_auc\",\n",
    "            \"task\": \"classification\",\n",
    "            \"eval_method\": \"cv\",\n",
    "            \"n_splits\": 5,\n",
    "            \"seed\": seed,\n",
    "            \"log_file_name\": f\"flaml_rf_seed{seed}_{class_name.replace(' ', '_')}.log\",\n",
    "            \"estimator_list\": [\"rf\"],       # << only RandomForest\n",
    "            \"model_history\": False\n",
    "        }\n",
    "\n",
    "        automl_rf.fit(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train_ovr,\n",
    "            **automl_settings_rf\n",
    "        )\n",
    "\n",
    "        rf_objects[class_name] = automl_rf\n",
    "        print(f\"Best RF model for '{class_name}': {automl_rf.best_estimator}\")\n",
    "\n",
    "        y_proba = automl_rf.predict_proba(X_test)[:, 1]\n",
    "        y_pred  = automl_rf.predict(X_test)\n",
    "        acc     = accuracy_score(y_test_ovr, y_pred)\n",
    "        auc     = roc_auc_score(y_test_ovr, y_proba)\n",
    "\n",
    "        print(f\"Accuracy: {acc:.4f} | ROC AUC: {auc:.4f}\")\n",
    "\n",
    "        roc_df = pd.DataFrame({\n",
    "            \"y_true\": y_test_ovr.astype(int),\n",
    "            \"y_score\": y_proba.astype(float)\n",
    "        })\n",
    "        roc_path = os.path.join(out_dir, f\"seed{seed}_{class_name.replace(' ', '_')}.csv\")\n",
    "        roc_df.to_csv(roc_path, index=False)\n",
    "\n",
    "        rf_auc_by_seed[class_name].append(auc)  # NEW: record per-seed AUC\n",
    "\n",
    "        rf_results[class_name] = {\n",
    "            \"y_test\": y_test_ovr,\n",
    "            \"y_pred_proba\": y_proba,\n",
    "            \"roc_auc\": auc\n",
    "        }\n",
    "\n",
    "    # Save RF results\n",
    "    with open(f'rf_results_genes_demo_{seed}.pkl', 'wb') as f:\n",
    "        pickle.dump(rf_results, f)\n",
    "\n",
    "    print(\"RF baseline results saved successfully.\")\n",
    "\n",
    "\n",
    "# ---- Summary over seeds (new) ----\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rows = []\n",
    "for cls, aucs in rf_auc_by_seed.items():\n",
    "    rows.append({\n",
    "        \"Model\": \"RandomForest\",\n",
    "        \"Class\": cls,\n",
    "        \"Mean_ROC_AUC\": float(np.mean(aucs)),\n",
    "        \"Std_ROC_AUC\": float(np.std(aucs)),\n",
    "        \"N_splits\": len(aucs)\n",
    "    })\n",
    "\n",
    "rf_summary_df = pd.DataFrame(rows)\n",
    "rf_summary_df.to_csv(\"rf_results_genes_demo_summary.csv\", index=False)\n",
    "print(rf_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# ---- Mean ROC across seeds from saved CSVs ----\n",
    "folder = \"/Users/authorname/Desktop/Projects/ml4h_project/RF(Genes+Demo)\"\n",
    "files = glob.glob(os.path.join(folder, \"seed*_*.csv\"))\n",
    "assert len(files) > 0, \"No per-seed ROC CSVs found in RF(Genes+Demo).\"\n",
    "\n",
    "# Infer class names from filenames (everything after 'seedX_')\n",
    "def class_from_path(p):\n",
    "    base = os.path.basename(p)\n",
    "    return \"_\".join(base.split(\"_\")[1:]).rsplit(\".csv\", 1)[0]  # e.g., 'Typical_AD'\n",
    "\n",
    "class_names = sorted(set(class_from_path(p) for p in files))\n",
    "\n",
    "fpr_grid = np.linspace(0.0, 1.0, 200)  # common grid for interpolation\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for cls in class_names:\n",
    "    cls_files = sorted(glob.glob(os.path.join(folder, f\"seed*_{cls}.csv\")))\n",
    "    if not cls_files:\n",
    "        continue\n",
    "\n",
    "    tprs_interp, aucs = [], []\n",
    "\n",
    "    for path in cls_files:\n",
    "        df = pd.read_csv(path)\n",
    "        y_true  = df[\"y_true\"].astype(int).values\n",
    "        y_score = df[\"y_score\"].astype(float).values\n",
    "\n",
    "        # EXACTLY like your ratios plots: no FPR de-dup\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "\n",
    "        # Interpolate TPR on common grid (no forcing tpr[-1] = 1.0)\n",
    "        tpr_i = np.interp(fpr_grid, fpr, tpr)\n",
    "        tpr_i[0] = 0.0\n",
    "        tprs_interp.append(tpr_i)\n",
    "\n",
    "        # AUC on raw fpr/tpr\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    std_tpr  = np.std(tprs_interp, axis=0)\n",
    "    mean_auc = float(np.mean(aucs))\n",
    "    std_auc  = float(np.std(aucs))\n",
    "\n",
    "    plt.plot(fpr_grid, mean_tpr, lw=2,\n",
    "             label=f\"{cls.replace('_',' ')} (AUC = {mean_auc:.3f} ± {std_auc:.3f})\")\n",
    "    plt.fill_between(fpr_grid,\n",
    "                     np.clip(mean_tpr - std_tpr, 0, 1),\n",
    "                     np.clip(mean_tpr + std_tpr, 0, 1),\n",
    "                     alpha=0.15)\n",
    "\n",
    "# Chance line\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Chance (AUC = 0.50)')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Random Forest (Genes+Demo)')\n",
    "plt.legend(loc='lower right', fontsize=9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1, 2, 3, 4, 5,]\n",
    "\n",
    "from collections import defaultdict\n",
    "lgbm_auc_by_seed = defaultdict(list)\n",
    "\n",
    "import os\n",
    "out_dir = \"/Users/authorname/Desktop/Projects/ml4h_project/LGBM(Genes+Demo)\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "from pathlib import Path\n",
    "def safe_cls(c): return c.replace(\"+\",\"plus\").replace(\" \",\"_\").replace(\"/\",\"-\")\n",
    "\n",
    "# REPLACE your existing sss+for-header with the two lines below:\n",
    "for seed in seeds:  \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=seed)\n",
    "    for train_index, test_index in sss.split(X_gene_based, y_strat):\n",
    "        X_train, X_test = X_gene_based.iloc[train_index], X_gene_based.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Keep track of patient IDs for GNN mapping\n",
    "        train_projids = df_qc.iloc[train_index]['projid']\n",
    "        test_projids = df_qc.iloc[test_index]['projid']\n",
    "\n",
    "\n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Test set shape: {X_test.shape}\")\n",
    "    print(\"Label to Class Name mapping:\")\n",
    "    for i, class_name in enumerate(label_encoder.classes_):\n",
    "        print(f\"{i}: {class_name}\")\n",
    "\n",
    "    from flaml import AutoML\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "\n",
    "    \n",
    "\n",
    "    # =============================================================================\n",
    "    # SECTION 3b: AutoML with FLAML (ONE-VS-REST) - Random Forest Baseline\n",
    "    # =============================================================================\n",
    "    print(\"\\n\\n--- Training AutoML LGBM (One-vs-Rest) ---\")\n",
    "\n",
    "    lgbm_results = {}\n",
    "    lgbm_objects = {}\n",
    "\n",
    "\n",
    "\n",
    "    for i, class_name in enumerate(label_encoder.classes_):\n",
    "        print(f\"\\n--- RF baseline for class: '{class_name}' vs. Rest ---\")\n",
    "        \n",
    "        y_train_ovr = (y_train == i).astype(int)\n",
    "        y_test_ovr  = (y_test  == i).astype(int)\n",
    "\n",
    "        if np.sum(y_test_ovr) < 1:\n",
    "            print(f\"Skipping class '{class_name}' due to no positive samples in the test set.\")\n",
    "            continue\n",
    "\n",
    "        automl_lgbm = AutoML()\n",
    "        automl_settings_lgbm = {\n",
    "            \"time_budget\": 100,\n",
    "            \"metric\": \"roc_auc\",\n",
    "            \"task\": \"classification\",\n",
    "            \"eval_method\": \"cv\",\n",
    "            \"n_splits\": 5,\n",
    "            \"seed\": seed,\n",
    "            \"log_file_name\": f\"flaml_lgbm_seed{seed}_{class_name.replace(' ', '_')}.log\",\n",
    "            \"estimator_list\": [\"lgbm\"],       # << only RandomForest\n",
    "            \"model_history\": False\n",
    "        }\n",
    "\n",
    "        automl_lgbm.fit(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train_ovr,\n",
    "            **automl_settings_lgbm\n",
    "        )\n",
    "\n",
    "        lgbm_objects[class_name] = automl_lgbm\n",
    "        print(f\"Best LGBM model for '{class_name}': {automl_lgbm.best_estimator}\")\n",
    "\n",
    "        y_proba = automl_lgbm.predict_proba(X_test)[:, 1]\n",
    "        y_pred  = automl_lgbm.predict(X_test)\n",
    "        acc     = accuracy_score(y_test_ovr, y_pred)\n",
    "        auc     = roc_auc_score(y_test_ovr, y_proba)\n",
    "\n",
    "        print(f\"Accuracy: {acc:.4f} | ROC AUC: {auc:.4f}\")\n",
    "\n",
    "        roc_df = pd.DataFrame({\n",
    "            \"y_true\": y_test_ovr.astype(int),\n",
    "            \"y_score\": y_proba.astype(float)\n",
    "        })\n",
    "        roc_path = os.path.join(out_dir, f\"seed{seed}_{class_name.replace(' ', '_')}.csv\")\n",
    "        roc_df.to_csv(roc_path, index=False)\n",
    "\n",
    "        lgbm_auc_by_seed[class_name].append(auc)  # NEW: record per-seed AUC\n",
    "\n",
    "        lgbm_results[class_name] = {\n",
    "            \"y_test\": y_test_ovr,\n",
    "            \"y_pred_proba\": y_proba,\n",
    "            \"roc_auc\": auc\n",
    "        }\n",
    "    \n",
    "        pkl_path = os.path.join(out_dir, f\"seed{seed}_{safe_cls(class_name)}_automl.pkl\")\n",
    "        with open(pkl_path, \"wb\") as f:\n",
    "            pickle.dump(automl_lgbm, f)\n",
    "\n",
    "    # # Save LGBM results\n",
    "    # with open(f'lgbm_results_genes_demo_{seed}.pkl', 'wb') as f:\n",
    "    #     pickle.dump(lgbm_results, f)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"LGBM baseline results saved successfully.\")\n",
    "\n",
    "\n",
    "# ---- Summary over seeds (new) ----\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rows = []\n",
    "for cls, aucs in lgbm_auc_by_seed.items():\n",
    "    rows.append({\n",
    "        \"Model\": \"LGBM\",\n",
    "        \"Class\": cls,\n",
    "        \"Mean_ROC_AUC\": float(np.mean(aucs)),\n",
    "        \"Std_ROC_AUC\": float(np.std(aucs)),\n",
    "        \"N_splits\": len(aucs)\n",
    "    })\n",
    "\n",
    "lgbm_summary_df = pd.DataFrame(rows)\n",
    "lgbm_summary_df.to_csv(\"lgbm_results_genes_demo_summary.csv\", index=False)\n",
    "print(lgbm_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# ---- Mean ROC across seeds from saved CSVs ----\n",
    "folder = \"/Users/authorname/Desktop/Projects/ml4h_project/LGBM(Genes+Demo)\"\n",
    "files = glob.glob(os.path.join(folder, \"seed*_*.csv\"))\n",
    "assert len(files) > 0, \"No per-seed ROC CSVs found in LGBM(Genes+Demo).\"\n",
    "\n",
    "# Infer class names from filenames (everything after 'seedX_')\n",
    "def class_from_path(p):\n",
    "    base = os.path.basename(p)\n",
    "    return \"_\".join(base.split(\"_\")[1:]).rsplit(\".csv\", 1)[0]  # e.g., 'Typical_AD'\n",
    "\n",
    "class_names = sorted(set(class_from_path(p) for p in files))\n",
    "\n",
    "fpr_grid = np.linspace(0.0, 1.0, 200)  # common grid for interpolation\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for cls in class_names:\n",
    "    cls_files = sorted(glob.glob(os.path.join(folder, f\"seed*_{cls}.csv\")))\n",
    "    if not cls_files:\n",
    "        continue\n",
    "\n",
    "    tprs_interp, aucs = [], []\n",
    "\n",
    "    for path in cls_files:\n",
    "        df = pd.read_csv(path)\n",
    "        y_true  = df[\"y_true\"].astype(int).values\n",
    "        y_score = df[\"y_score\"].astype(float).values\n",
    "\n",
    "        # EXACTLY like your ratios plots: no FPR de-dup, no forcing tpr[-1]=1.0\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "\n",
    "        # Interpolate TPR on common grid (just set start to 0.0 like your ratios script)\n",
    "        tpr_i = np.interp(fpr_grid, fpr, tpr)\n",
    "        tpr_i[0] = 0.0\n",
    "        tprs_interp.append(tpr_i)\n",
    "\n",
    "        # AUC on raw fpr/tpr\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "\n",
    "    if not tprs_interp:\n",
    "        continue\n",
    "\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    std_tpr  = np.std(tprs_interp, axis=0)\n",
    "    mean_auc = float(np.mean(aucs))\n",
    "    std_auc  = float(np.std(aucs))\n",
    "\n",
    "    plt.plot(\n",
    "        fpr_grid, mean_tpr, lw=2,\n",
    "        label=f\"{cls.replace('_',' ')} (AUC = {mean_auc:.3f} ± {std_auc:.3f})\"\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        fpr_grid,\n",
    "        np.clip(mean_tpr - std_tpr, 0, 1),\n",
    "        np.clip(mean_tpr + std_tpr, 0, 1),\n",
    "        alpha=0.15\n",
    "    )\n",
    "\n",
    "# Chance line\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Chance (AUC = 0.50)')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('LGBM (Genes+Demo)')\n",
    "plt.legend(loc='lower right', fontsize=9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neuro_240)",
   "language": "python",
   "name": "neuro_240"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
