{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BLOCK A â€” PREPROCESSING (GENE-SUMMED DOSAGES; MATCHES YOUR BASELINE)\n",
    "# =========================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"--- Starting Data Preprocessing (gene-summed SNP dosages) ---\")\n",
    "\n",
    "# --- File paths (your originals) ---\n",
    "main_data_path    = '/Users/authorname/Downloads/all_chr_merged.parquet'\n",
    "gwas_catalog_path = '/Users/authorname/Downloads/MONDO_0004975_associations_export.tsv'\n",
    "string_links_path = '/Users/authorname/Downloads/9606.protein.links.v12.0.txt'      # unused here\n",
    "string_info_path  = '/Users/authorname/Downloads/9606.protein.info.v12.0.txt'       # unused here\n",
    "\n",
    "out_dir = \"/Users/authorname/Desktop/Projects/Genomics_LGBM(Genomics+Meta)_RATIOS_fixed_rfe\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# --- Load SNP matrix + GWAS mapping (your logic) ---\n",
    "df = pd.read_parquet(main_data_path)\n",
    "gwas_df = pd.read_csv(gwas_catalog_path, sep='\\t')\n",
    "\n",
    "gwas_df['riskAllele_cleaned'] = gwas_df['riskAllele'].astype(str).str.split('-').str[0].str.strip()\n",
    "gwas_df['first_gene'] = gwas_df['mappedGenes'].astype(str).str.split(',').str[0].str.strip()\n",
    "rs_map = gwas_df.dropna(subset=['riskAllele_cleaned', 'first_gene']) \\\n",
    "                .set_index('riskAllele_cleaned')['first_gene'].to_dict()\n",
    "\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "snp_cols = [c for c in df.columns if c.startswith('rs') or c.startswith('chr')]\n",
    "all_mapped_snps = {s: rs_map.get(s.split('_')[0]) for s in snp_cols if rs_map.get(s.split('_')[0])}\n",
    "\n",
    "# --- SNP QC (same thresholds as baseline) ---\n",
    "print(\"\\n--- SNP QC ---\")\n",
    "snps_to_map = list(all_mapped_snps.keys())\n",
    "maf = df[snps_to_map].apply(\n",
    "    lambda x: (2*x.eq(2).sum() + x.eq(1).sum()) / (2*x.notna().sum()),\n",
    "    axis=0\n",
    ")\n",
    "snps_to_remove_maf = maf[maf < 0.01].index.tolist()\n",
    "\n",
    "missing_rates = df[snps_to_map].isna().mean()\n",
    "snps_to_remove_callrate = missing_rates[missing_rates > 0.05].index.tolist()\n",
    "\n",
    "all_snps_to_remove = set(snps_to_remove_maf + snps_to_remove_callrate)\n",
    "all_mapped_snps_qc = {snp: gene for snp, gene in all_mapped_snps.items() if snp not in all_snps_to_remove}\n",
    "\n",
    "df_qc = df.drop(columns=list(all_snps_to_remove), errors=\"ignore\")\n",
    "snp_cols_qc = list(all_mapped_snps_qc.keys())\n",
    "print(f\"Retained {len(snp_cols_qc)} SNPs after QC.\")\n",
    "\n",
    "# --- Label assignment (your definitions) ---\n",
    "print(\"\\n--- Label assignment ---\")\n",
    "df_qc['age_death'] = pd.to_numeric(df_qc['age_death'].astype(str).replace('90+', '90', regex=False), errors='coerce')\n",
    "\n",
    "conditions = [\n",
    "    (df_qc['ceradsc'].isin([1, 2])) & (df_qc['cogdx'].isin([4, 5])),\n",
    "    (df_qc['ceradsc'].isin([1, 2])) & ~(df_qc['cogdx'].isin([4, 5])),\n",
    "    ~(df_qc['ceradsc'].isin([1, 2])) & (df_qc['cogdx'].isin([4, 5])),\n",
    "    ~(df_qc['ceradsc'].isin([1, 2])) & ~(df_qc['cogdx'].isin([4, 5]))\n",
    "]\n",
    "choices = ['Typical AD', 'Resilient', 'Symptomatic Non-AD', 'Healthy Control']\n",
    "df_qc['patient_group'] = np.select(conditions, choices, default='Unknown')\n",
    "df_qc = df_qc[df_qc['patient_group'] != 'Unknown'].reset_index(drop=True)\n",
    "\n",
    "print(\"Patient Group Counts:\")\n",
    "print(df_qc['patient_group'].value_counts())\n",
    "\n",
    "# --- Demographics + SNP handling (mirror baseline) ---\n",
    "numeric_features     = ['age_death', 'educ']\n",
    "categorical_features = ['apoe_genotype']\n",
    "binary_features      = ['msex']\n",
    "snp_features         = snp_cols_qc\n",
    "\n",
    "feature_df = df_qc[['projid'] + numeric_features + categorical_features + binary_features + snp_features].copy()\n",
    "\n",
    "# Impute numeric only\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "feature_df[numeric_features] = imputer_num.fit_transform(feature_df[numeric_features])\n",
    "\n",
    "# Keep SNP NaNs; round observed to {0,1,2}\n",
    "snp_block = feature_df[snp_features].astype(float)\n",
    "mask = ~snp_block.isna()\n",
    "rounded = np.empty_like(snp_block.values)\n",
    "rounded[:] = np.nan\n",
    "rounded[mask.values] = np.rint(snp_block.values[mask.values])\n",
    "snp_block = pd.DataFrame(rounded, columns=snp_features, index=feature_df.index)\n",
    "feature_df[snp_features] = snp_block\n",
    "\n",
    "feature_df[binary_features] = feature_df[binary_features].astype(int)\n",
    "\n",
    "# Sum SNPs â†’ genes (ignore NaN; keep NaN if all missing)\n",
    "print(\"\\n--- Building gene-summed dosage matrix ---\")\n",
    "gene_to_snps = defaultdict(list)\n",
    "for snp, gene in all_mapped_snps_qc.items():\n",
    "    gene_to_snps[gene].append(snp)\n",
    "\n",
    "gene_dosage_df = pd.DataFrame(index=feature_df.index)\n",
    "for gene, snp_list in gene_to_snps.items():\n",
    "    vals = feature_df[snp_list].to_numpy(dtype=float)\n",
    "    gsum = np.nansum(vals, axis=1)\n",
    "    all_missing = np.isnan(vals).all(axis=1)\n",
    "    gsum[all_missing] = np.nan\n",
    "    gene_dosage_df[gene] = gsum\n",
    "\n",
    "# APOE OHE\n",
    "try:\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "apoe_encoded = ohe.fit_transform(feature_df[['apoe_genotype']])\n",
    "apoe_df = pd.DataFrame(apoe_encoded, columns=ohe.get_feature_names_out(), index=feature_df.index)\n",
    "\n",
    "# Final feature table: demographics + APOE OHE + gene_sums\n",
    "X_gene_based = pd.concat(\n",
    "    [feature_df[numeric_features + binary_features].reset_index(drop=True),\n",
    "     apoe_df.reset_index(drop=True),\n",
    "     gene_dosage_df.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "X_gene_based.columns = X_gene_based.columns.astype(str)\n",
    "\n",
    "# Labels & encoders (to match your baseline later)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_qc['patient_group'].astype(str).values)\n",
    "y_labels = df_qc['patient_group'].astype(str).values\n",
    "\n",
    "# Stratifier exactly like your baseline\n",
    "y_strat = (df_qc['patient_group'].astype(str) + \"_\" + df_qc['msex'].astype(int).astype(str)).values\n",
    "\n",
    "# Keep list of pure gene columns (for ratio generation later)\n",
    "non_gene_cols = set(numeric_features + binary_features + list(apoe_df.columns))\n",
    "gene_cols = [c for c in X_gene_based.columns if c not in non_gene_cols]\n",
    "\n",
    "# Groups if needed elsewhere\n",
    "groups = df_qc['projid'].astype(str).values\n",
    "\n",
    "print(f\"\\nX_gene_based shape: {X_gene_based.shape}\")\n",
    "print(\"Label to Class Name mapping:\")\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i}: {class_name}\")\n",
    "print(f\"Total genes available for ratio generation: {len(gene_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BLOCK B â€” READ BASELINE GENOMICS PICKLES & COLLECT STABLE GENES\n",
    "# =========================\n",
    "import os, pickle\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "print(\"\\n--- Reading baseline GENOMICS LGBM pickles for stable features (â‰¥2/5 seeds) ---\")\n",
    "\n",
    "baseline_models_dir = \"/Users/authorname/Desktop/Projects/ml4h_project/LGBM(Genes+Demo)\"\n",
    "\n",
    "# Match EXACT names you saved with in baseline training\n",
    "classes = [\n",
    "    \"Healthy_Control\",\n",
    "    \"Resilient\",\n",
    "    \"Symptomatic_Non-AD\",   # note the dash\n",
    "    \"Typical_AD\"\n",
    "]\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "\n",
    "def _get_trained_estimator_and_features(automl_obj):\n",
    "    model = getattr(automl_obj, \"model\", None)\n",
    "    est = getattr(model, \"estimator\", model)\n",
    "    if est is None:\n",
    "        return None, None\n",
    "    if hasattr(automl_obj, \"feature_names_in_\") and automl_obj.feature_names_in_ is not None:\n",
    "        feat_names = list(automl_obj.feature_names_in_)\n",
    "    elif hasattr(est, \"feature_name_\") and est.feature_name_ is not None:\n",
    "        feat_names = list(est.feature_name_)\n",
    "    else:\n",
    "        feat_names = None\n",
    "    return est, feat_names\n",
    "\n",
    "feature_counts_per_class = defaultdict(Counter)\n",
    "\n",
    "for seed in seeds:\n",
    "    for cls in classes:\n",
    "        pkl_path = os.path.join(baseline_models_dir, f\"seed{seed}_{cls}_automl.pkl\")\n",
    "        if not os.path.exists(pkl_path):\n",
    "            print(f\"[WARN] Missing: {pkl_path}\")\n",
    "            continue\n",
    "        try:\n",
    "            with open(pkl_path, \"rb\") as f:\n",
    "                automl = pickle.load(f)\n",
    "            est, feature_names = _get_trained_estimator_and_features(automl)\n",
    "            if est is None or not hasattr(est, \"feature_importances_\"):\n",
    "                print(f\"[WARN] No feature importances in {pkl_path}\")\n",
    "                continue\n",
    "            importances = est.feature_importances_\n",
    "            nonzero_genes = [f for f, imp in zip(feature_names, importances) if imp > 0 and f in gene_cols]\n",
    "            feature_counts_per_class[cls].update(nonzero_genes)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {pkl_path}: {e}\")\n",
    "\n",
    "# keep genes seen in â‰¥2 seeds\n",
    "shared_features_per_class = {\n",
    "    cls: [feat for feat, cnt in cnts.items() if cnt >= 2]\n",
    "    for cls, cnts in feature_counts_per_class.items()\n",
    "}\n",
    "\n",
    "for cls in classes:\n",
    "    feats = shared_features_per_class.get(cls, [])\n",
    "    print(f\"[{cls}] Stable genes (â‰¥2 seeds): {len(feats)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BLOCK C â€” RATIO TRAINING WITH RFE (GENE-BASED) - CORRECTED\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "out_dir = \"/Users/authorname/Desktop/Projects/Genomics_LGBM(Genomics+Meta)_RATIOS_fixed_rfe\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# ---- Config (assumes variables from Blocks A & B are loaded) ----\n",
    "# `out_dir`, `label_encoder`, `y_labels`, `y_strat`, `groups`,\n",
    "# `X_gene_based`, `gene_cols`, and `shared_features_per_class`\n",
    "# should all be available from the previous blocks.\n",
    "\n",
    "# --- ðŸ’¡ FIX: Use the class names with underscores to match the keys ---\n",
    "# --- in the `shared_features_per_class` dictionary from Block B. ---\n",
    "classes = [\n",
    "    \"Healthy_Control\",\n",
    "    \"Resilient\",\n",
    "    \"Symptomatic_Non-AD\",\n",
    "    \"Typical_AD\"\n",
    "]\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "\n",
    "def safe_cls(c):\n",
    "    return c.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "\n",
    "# ---- Gene-only matrix for creating ratios ----\n",
    "X_genes_only = X_gene_based[gene_cols].copy()\n",
    "\n",
    "# ---- Custom group-aware stratified split function (no changes needed) ----\n",
    "def group_stratified_shuffle_split(df_index, strata_all, groups_all, test_size=0.30, random_state=0):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    data = pd.DataFrame({\"idx\": df_index, \"strata\": strata_all, \"group\": groups_all})\n",
    "    grp_mode = data.groupby(\"group\")[\"strata\"].agg(lambda s: s.value_counts().idxmax())\n",
    "    grp_mode = grp_mode.sample(frac=1.0, random_state=random_state)\n",
    "\n",
    "    train_groups, test_groups = [], []\n",
    "    for _, grp_ids in grp_mode.groupby(grp_mode.values):\n",
    "        g_list = list(grp_ids.index)\n",
    "        rng.shuffle(g_list)\n",
    "        n_test = max(1, int(round(test_size * len(g_list))))\n",
    "        test_groups.extend(g_list[:n_test])\n",
    "        train_groups.extend(g_list[n_test:])\n",
    "\n",
    "    train_mask = np.isin(groups_all, train_groups)\n",
    "    test_mask  = np.isin(groups_all, test_groups)\n",
    "    return np.where(train_mask)[0], np.where(test_mask)[0]\n",
    "\n",
    "# ---- Main Training Loop ----\n",
    "for cls in classes:\n",
    "    # 1. Select stable genes for the current class\n",
    "    # Now, `cls` will be \"Healthy_Control\", which correctly finds the 7 genes.\n",
    "    class_genes = shared_features_per_class.get(cls, [])\n",
    "    print(f\"\\n[{cls}] Using {len(class_genes)} stable genes for ratio generation...\")\n",
    "\n",
    "    if len(class_genes) < 2:\n",
    "        print(f\"-> Skipping [{cls}]: Not enough genes to form ratios (need at least 2).\")\n",
    "        continue\n",
    "\n",
    "    # 2. Generate all pairwise ratios from the selected genes\n",
    "    ratio_cols = []\n",
    "    ratio_data = []\n",
    "    epsilon = 1e-8  # Small value to prevent division by zero\n",
    "\n",
    "    for g1, g2 in combinations(class_genes, 2):\n",
    "        rname = f\"{g1}_div_{g2}\"\n",
    "        ratio_cols.append(rname)\n",
    "        # Add epsilon for numerical stability\n",
    "        ratio_data.append(X_genes_only[g1].values / (X_genes_only[g2].values + epsilon))\n",
    "\n",
    "    X_ratio_cls = pd.DataFrame(np.column_stack(ratio_data), columns=ratio_cols, index=X_genes_only.index)\n",
    "    print(f\"-> Generated {X_ratio_cls.shape[1]} ratio features for [{cls}].\")\n",
    "\n",
    "    # 3. Loop through seeds to perform train/test split, RFE, and model training\n",
    "    for seed in seeds:\n",
    "        # A. Split data into training and testing sets\n",
    "        tr_idx, te_idx = group_stratified_shuffle_split(\n",
    "            df_index=np.arange(len(X_ratio_cls)),\n",
    "            strata_all=y_strat,\n",
    "            groups_all=groups,\n",
    "            test_size=0.30,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "        # B. Create initial data splits with all generated ratios\n",
    "        X_train_full = X_ratio_cls.iloc[tr_idx]\n",
    "        X_test_full  = X_ratio_cls.iloc[te_idx]\n",
    "        y_train_full = pd.Series(y_labels).iloc[tr_idx].values\n",
    "        y_test_full  = pd.Series(y_labels).iloc[te_idx].values\n",
    "\n",
    "        print(f\"[{cls} | Seed {seed}] Train/Test split: {len(tr_idx)} / {len(te_idx)}\")\n",
    "\n",
    "        # C. Create binary labels for one-vs-all classification\n",
    "        # We must convert the underscore version back to the space version to match `y_labels`\n",
    "        y_train = (y_train_full == cls.replace(\"_\", \" \")).astype(int)\n",
    "        y_test  = (y_test_full == cls.replace(\"_\", \" \")).astype(int)\n",
    "\n",
    "\n",
    "        # D. Perform RFE on the TRAINING data ONLY\n",
    "        rfe_model = LGBMClassifier(n_estimators=100, random_state=seed)\n",
    "        n_select  = min(100, X_train_full.shape[1]) # Select up to 100 features\n",
    "        rfe = RFE(estimator=rfe_model, n_features_to_select=n_select, step=0.1)\n",
    "        rfe.fit(X_train_full, y_train)\n",
    "\n",
    "        # E. Filter both train and test sets using the features selected by RFE\n",
    "        selected_cols = list(X_train_full.columns[rfe.get_support()])\n",
    "        X_train = X_train_full[selected_cols]\n",
    "        X_test  = X_test_full[selected_cols]\n",
    "        print(f\"-> Post-RFE features selected: {len(selected_cols)}\")\n",
    "\n",
    "        # F. Train the final model using AutoML\n",
    "        automl = AutoML()\n",
    "        settings = {\n",
    "            \"time_budget\": 100,\n",
    "            \"metric\": \"roc_auc\",\n",
    "            \"task\": \"classification\",\n",
    "            \"eval_method\": \"cv\",\n",
    "            \"estimator_list\": [\"lgbm\"],\n",
    "            \"log_file_name\": os.path.join(out_dir, f\"flaml_seed{seed}_{safe_cls(cls)}.log\"),\n",
    "            \"seed\": seed,\n",
    "        }\n",
    "\n",
    "        automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "        automl.pickle(os.path.join(out_dir, f\"seed{seed}_{safe_cls(cls)}_automl.pkl\"))\n",
    "\n",
    "        # G. Evaluate performance and save results\n",
    "        y_score = automl.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_score) if (y_test.sum() > 0 and y_test.sum() < len(y_test)) else float(\"nan\")\n",
    "        print(f\"  -> FINAL AUC = {auc:.4f}\\n\")\n",
    "\n",
    "        out_csv = os.path.join(out_dir, f\"seed{seed}_{safe_cls(cls)}.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"y_true\": y_test.astype(int),\n",
    "            \"y_score\": y_score.astype(float)\n",
    "        }).to_csv(out_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neuro_240)",
   "language": "python",
   "name": "neuro_240"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
